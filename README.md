# Spark for Java Developers course

[Udemy - Spark for Java Developers](https://www.udemy.com/course/apache-spark-for-java-developers)

-------------------------------------------------------------
### Requirements:
* JDK 8 ( no support for JDK 9 )
* Lambda syntax

### Modules:
* Spark RDD ( Resilient Distributed Dataset )
* Spark SQL
  * Data Frames API
  * data science
* Spark ML ( Machine Learning )
* Spark Streaming
  * streams
  * apache kafka

### Functions:
* reduce
* map
* count


-------------------------------------------------------------
### Abbreviations:
* RDD Resilient Distributed Dataset
* HDFS Hadoop Distributed File System
  * HDFS provides better data throughput than traditional file systems, in addition to high fault tolerance and native support of large datasets
* YARN Yet Another Resource Negotiator – Manages and monitors cluster nodes and resource usage. It schedules jobs and tasks of HDFS
* MapReduce – A framework that helps programs do the parallel computation on data.
  * The map task takes input data and converts it into a dataset that can be computed in key value pairs.
  * The output of the map task is consumed by reduce tasks to aggregate output and provide the desired result.
* Spark – An open source, distributed processing system commonly used for big data workloads.
  * Apache Spark uses in-memory caching and optimized execution for fast performance, and it supports general batch processing, streaming analytics, machine learning, graph databases, and ad hoc queries
* DAG Directed Acyclic Graph - jargon for execution plan


